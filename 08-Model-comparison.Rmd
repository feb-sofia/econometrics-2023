---
title: "Model Comparison"
author: "Boyko Amarov"
date: "2023-05-28"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

```{r}
# install.packages(c("tidyverse", "caret"))
library(tidyverse)
library(caret)
```

# Model comparison

## Data

When the goal of the model is prediction, we need a way to make an
educated guess about the model performance on data that it has not yet
seen.

Let us consider a model:

$$
y_i = 2 + 3 x_i + 2 x_i^2 + e_i, e_i \sim N(0, 1.5^2)
$$

And let us simulate data from this model. We will use the first 100
observations to fit (train) the model. The rest of the data will serve
as a test set.

```{r}
set.seed(1235)

n_sim <- 200
n_train <- 100
n_test <- n_sim - n_train

dt_all <- tibble(
  x = runif(n = n_sim, min = -2, max = 2),
  y = 2 + 3 * x + 2 * x^2 + rnorm(n = n_sim, mean = 0, sd = 1.5)
)

trainIndex <- createDataPartition(dt_all$y, p=0.8, list=FALSE)

dt_train <- dt_all[trainIndex, ]
dt_test <- dt_all[-trainIndex, ]
```

```{r}
dt_train %>%
  ggplot(aes(x = x, y = y)) + 
  geom_point() +
  geom_smooth(method = "lm")
```

```{r}
fit <- lm(y ~ 1 + x, data = dt_train)
summary(fit)
```

```{r}
mean(dt_train$y)
```

```{r}
7.43 - 2*0.30
7.43 + 2*0.30
```

```{r}
predict(fit, newdata = tibble(x = 1), interval = "confidence")
```

```{r}
predict(fit, newdata = tibble(x = 1), interval = "prediction")
```

```{r}
predict(fit, newdata = tibble(x = 1), se.fit = TRUE)
```

```{r}
rnorm(n = 1, mean = 7.43, sd = 1.5)
```

The $R^2$ is a measure of goodness of fit to the *observed* data that
was used when fitting the model.

$$
R^2 = 1 - \frac{\text{RSS}}{\text{TSS}} \\
RSS = \sum_{i = 1}^n (y_i - \hat{y}_i)^2 \\
TSS = \sum_{i = 1}^n (y_i - \bar{y})^2
$$

## Confidence and prediction intervals

```{r}
predict(fit, newdata = tibble(x = 3))
```

A prediction of new values of $y$ based on a linear model has two
sources of uncertainty. The first one is the estimation of the mean of
$y$ at some predictor value.

$$
y_i = \beta_0 + \beta_1 x_{1i} + \ldots + \beta_p x_{pi} + e_i, \quad e_i \sim N(0, \sigma^2)
$$ 

This is equivalent to

$$
y_i \sim N(\mu_i, \sigma^2)\\
\mu_i = \beta_0 + \beta_1 x_{1i} + \ldots + \beta_2 x_{pi}
$$

The estimated regression equation is:

$$
\hat{y}_i = \hat{\mu}_i = \hat{\beta}_0 + \hat{\beta}_1 x_{1i} + \ldots + \hat{\beta}_2 x_{pi}
$$ 

The standard deviation of the error term can be estimated with the
residual standard error:

$$
\hat{\sigma} = \sqrt{\frac{\text{RSS}}{n - (p + 1)}}
$$

where $p + 1$ is the number of coefficients in the model (the constant and the coefficients of the predictors). Therefore
under the model we expect $y$ to follow a normal distribution:

$$
y \sim N(\hat{\mu}, \hat{\sigma}^2)
$$

The uncertainty about the mean of $y$ can be expressed with the
confidence interval.

$$
P(\hat{\mu} - t_{1 - \alpha / 2, n - (p + 1)}se(\hat{\mu}) \leq \mu \leq \hat{\mu} + t_{1 - \alpha / 2, n - (p + 1)} se(\hat{\mu})) \approx 1 - \alpha
$$

In addition, the prediction interval accounts for the uncertainty of
sampling from a normal distribution.

```{r}
predict(fit, newdata = tibble(x = 2), se.fit = TRUE)
```

```{r}
predict(fit, newdata = tibble(x = 2), interval = "confidence")
```

```{r}
predict(fit, newdata = tibble(x = 2), interval = "prediction")
```

```{r}
rnorm(n = 1, mean = 13.83053, sd = 1.545079)
```

## Comparing nested models

In the model above we would like to test the hypothesis that the
coefficients of the polynomial terms of degree greater and including
three are simultaneously equal to zero.

```{r}
fit <- lm(y ~ 1 + poly(x, degree = 8, raw = TRUE), data = dt_train)
summary(fit)
```

```{r}
fit_reduced <- lm(y ~ 1 + poly(x, degree = 3, raw = TRUE), data = dt_train)
summary(fit_reduced)
```

```{r}
fit_int <- lm(y ~ 1, data = dt_train)
summary(fit_int)
anova(fit_int, fit_reduced)
```

A natural summary of the goodness of fit of the model are the residuals
and their sum of squares. This is the summary that OLS minimizes during
the model fitting. If two models (full, reduced) that differ by linear
constraints on their coefficients fit the data equally well, then the
difference of their RSS should be close to zero.

$$
RSS_{\text{reduced}} - RSS_{\text{full}}
$$ Note that the RSS of the full model will always be less of equal to
that of the reduced model.

It can be shown that an appropriately scaled version of this difference
follows a F distribution of $\text{df_\text{reduced}}$ and
$\text{df_{\full}}$ degrees of freedom

$$
f = \frac{\frac{RSS_{\text{reduced}} - RSS_{\text{full}}}{df_{\text{reduced}} - df_{\text{full}}}}{\frac{RSS_{\text{full}}}{df_{\text{full}}}}
$$ \frac{df_{\text{full}}}{df_{\text{reduced}} - df_{\text{full}}}

```{r}
anova(fit_reduced, fit)
```

```{r}
1 - pf(1.0703, df1 = 6, df2 = 151)
```
